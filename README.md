# Table of Contents

1. [Introduction](#introduction)
2. [Architecture Overview](#architecture-overview)
3. [Model Comparison](#model-comparison)
4. [Getting Started](#getting-started)
   * [Check the Running Environment](#1-check-the-running-environment)
   * [Installation and Dependencies](#2-installation-and-dependencies)
   * [Download Datasets](#3-download-datasets)
   * [Configuration](#4-configuration)
   * [Training the Model](#5-training-the-model)
5. [Project Structure](#project-structure)


*****


# ğŸ“‘Introduction

## Multi-Head Neural Networks for Financial Time Series Classification

This repository implements multi-head architectures for financial time series classification for bankruptcy prediction. It employs recurrent modelsâ€”LTC, CfC, LSTM, and GRUâ€”in a multi-head architecture to process multiple financial indicators concurrently. The code supports various preprocessing techniques, undersampling methods against class imbalance, and comprehensive evaluation metrics.


*****


# ğŸ”Architecture Overview

## Multi-Head Architecture

<img src="assets/architecture.png">

The core innovation is a multi-head design that processes each financial variable in its own network branch and then aggregates their outputs for final classification.

 > [!Note]
 > images and the papers are [here](https://www.mdpi.com/1999-5903/16/3/79)


### 1. Liquid Time-Constant Networks (LTC)
Continuous-time recurrent neural network with liquid time constants. Uses the [ncps](https://github.com/mlech26l/ncps) library for LTC implementation
- **Paper**: https://arxiv.org/pdf/2006.04439

### 2. Closed-form Continuous-time Networks (CfC)
Efficient continuous-time neural networks with closed-form solutions. Uses the [ncps](https://github.com/mlech26l/ncps) library with tanh activation
- **Paper**: https://arxiv.org/pdf/2106.13898

### 3. Long Short-Term Memory (LSTM)
Traditional recurrent neural network with memory cells

### 4. Gated Recurrent Unit (GRU)
Simplified recurrent neural network with gating mechanisms


*****


# ğŸ“‹Model Comparison

## Model Parameters

<div align="center">

| Model Type | Window Size | Hidden Size (Classifier) | Parameters |
|------------|-------------|--------------------------|------------|
| LTC        | 3, 4, 5     | 64                       | 4948, 6766, 8728 |
| CfC        | 3, 4, 5     | 64                       | 43162, 55906, 68650 |
| LSTM       | 3, 4, 5     | 64                       | 5074, 6946, 8962 |
| GRU        | 3, 4, 5     | 64                       | 4750, 6442, 8242 |

</div>


*****


# ğŸ”¨Getting Started

## 1. Check the Running Environment

Check your PyTorch installation:
```bash
python -c "import torch; print(torch.__version__); print('CUDA available:', torch.cuda.is_available())"
```

## 2. Installation and Dependencies

Clone the repository and install dependencies:

```bash
git clone https://github.com/gyb357/MultiHeadLNN
cd MultiHeadLNN
pip install -r requirements.txt
```

### Required Dependencies

torch, pandas, matplotlib, scikit-learn, ncps, rich, pyyaml

## 3. Download Datasets

You can download the dataset and related papers here:

```bash
https://github.com/sowide/multi-head_LSTM_for_bankruptcy-prediction
https://github.com/sowide/bankruptcy_dataset
```

 > [!Note]
 > The dataset is under a CC-BY-4.0 license. Please refer to the readme.md on the corresponding GitHub.

## 4. Configuration

Modify the `./config/configs.yaml` file to customize your experiment.

## 5. Training the Model

### Data Preparation

Ensure your dataset follows the expected structure:
- Place training data in `dataset/{window}_train.csv`
- Place validation data in `dataset/{window}_valid.csv`
- Place test data in `dataset/{window}_test.csv`

### Running Training

To train the model, run:

```bash
python main.py
```

### Results

Results are automatically saved to:
- `result/{ModelName}_results_{ScalerName}.csv`
- `result/best_model.pth` (best model checkpoint)

```bash
python plot.py
```


*****


# ğŸ“Project Structure

```
MultiHeadLNN/
â”œâ”€â”€ config/                 # Configuration files
â”‚   â””â”€â”€ configs.yaml        # Main configuration file
â”œâ”€â”€ dataset/                # Dataset directory
â”‚   â”œâ”€â”€ {window}_train.csv  # Training data for each window
â”‚   â”œâ”€â”€ {window}_valid.csv  # Validation data for each window
â”‚   â””â”€â”€ {window}_test.csv   # Test data for each window
â”œâ”€â”€ model/                  # Model architectures and utilities
â”‚   â”œâ”€â”€ classifier.py       # Classification head implementation
â”‚   â”œâ”€â”€ forward.py          # Forward pass utilities
â”‚   â”œâ”€â”€ lnn.py              # Liquid neural network implementations
â”‚   â”œâ”€â”€ rnn.py              # Traditional RNN implementations
â”‚   â””â”€â”€ utils.py            # Model utilities
â”œâ”€â”€ result/                 # Results and model checkpoints
â”‚   â”œâ”€â”€ best_model.pth      # Best model checkpoint
â”‚   â””â”€â”€ *_results_*.csv     # Experimental results
â”œâ”€â”€ dataset.py              # Data processing utilities
â”œâ”€â”€ main.py                 # Main training script
â”œâ”€â”€ plot.py                 # Visualization utilities
â”œâ”€â”€ train.py                # Training and evaluation functions
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # This file
```

